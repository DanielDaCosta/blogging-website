{
    "blogs": [
      {
        "title": "Evaluating Large Language Models on Code Generation",
        "body": "In this study, the performances in Python code generation of three different code generation models – CodeT5, CodeGen, and GPT-3.5 – were compared using the Mostly Basic Python Problems (MBPP) dataset. The pass@k metric was used as the primary method of evaluation, and CodeT5 and CodeGen were evaluated in a few-shot setting, while GPT-3.5 was evaluated in zero-shot and few-shot settings. The findings suggest that GPT-3.5 performs best in the few-shot setting, followed by GPT-3.5 in the zero-shot setting, CodeT5 in the few-shot setting, and CodeGen in the few-shot setting. These results indicate that GPT-3.5 is a promising model for code generation tasks, particularly in situations where the training data is limited, and highlight the importance of providing contextual information through prompting to overcome certain deficiencies in the zero-shot setting.",
        "author": "Daniel da Costa",
        "id": 1
      },
      {
        "title": "Recommendation System",
        "body": "The project consists of building different types of recommendation systems using the Yelp dataset to predict the ratings/stars for given user ids and business ids.",
        "author": "Daniel da Costa",
        "id": 2
      },
      {
        "title": "Datawarehouse Redshift",
        "body": "ETL pipeline for a datawarehouse (DWH) hosted on Redshift AWS.",
        "author": "Daniel da Costa",
        "id": 3
      },
      {
        "title": "Crypto Bot",
        "body": "Trading bot using RSI indicator for Binance Exchange.",
        "author": "Daniel da Costa",
        "id": 4
      },
      {
        "title": "Natural Language Generator",
        "body": "Generates sentences based on numerical inputs, taking into account: sensitiveness and intensity of the data.",
        "author": "Daniel da Costa",
        "id": 5
      }
    ]
  }